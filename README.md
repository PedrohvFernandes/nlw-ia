# NLW-IA 2023 - Rocketseat <img  align='center' width='100px' src='https://yt3.ggpht.com/ytc/AKedOLQkXnYChXAHOeBQLzwhk1_BHYgUXs6ITQOakoeNoQ=s176-c-k-c0x00ffffff-no-rj'/>

<p align='center'>
  <img src='https://storage.googleapis.com/star-lab/nlw-ia/OG.jpg'/>
</p>

## Sobre:

### Precisa de uma aplicaÃ§Ã£o para te sugerir algo sobre um video seu, seja um titulo, descriÃ§Ã£o... entÃ£o te apresento um projeto que tem por tras duas melhores IA ja inventadas da OPENAI, o chatgpt e a whisper-1, as duas trabalhando lado a lado conseguem gerar informaÃ§Ãµes do seu video de acordo com sua necessidade

## Conm funciona em termos tecnicos
#### Como Ã© gerado alguma descriÃ§Ã£o ou algo para o video? O usuario coloca o video que ele quer que seja gerado um texto final com base no audio daquele video, ao clicar no botÃ£o de UPLOAD, ele Ã© convertido para audio no propio front, apos isso vai executar de fato o upload, vai esperar a execuÃ§Ã£o do upload do audio, e para isso Ã© usado o pipeline e por conta do pipeline nao vai passar para uma proxima tarefa enquanto ele nao concluir de escrever o audio para a maquina local e mandar o path do arquivo na maquina local para o Banco de dados junto com o nome usando o prisma, depois a funÃ§Ã£o de transcription vai ser executada em create-transcription, ja com o id do video que acabou de subir e gerar o arquivo para o maquina local e o path do arquivo para banco de dados, com isso Ã© feito a conversao de audio para text usando alem do audio do video os prompts de transcriÃ§Ã£o para ajudar a IA entender melhor o audio do video com palavras mais difÃ­ceis, dps vai para o ultimo passo que Ã© o EXECUTAR, a onde esse texto Ã© usado no chatgpt com o prompt selecionado sem ser o de transcriÃ§Ã£o que nesse prompt vai conter o template que nada mais Ã©, Ã© o que voce quer que gere com base na transcriÃ§ao, vai ser usado tambem a temperatura que Ã© a onde voce decide se ela a IA vai ser mais criativa ou mais esperta sem erros e o id do video no generate-ai-completion: video->audio->text(whisper-1)->Prompt+Text:chatgpt podendo gerar uma descriÃ§Ã£o para o video que seria considerado o texto final, tudo vai depender do prompt usado, modelo(Ia que vai gerar o texto final) e a temperatura.

#### Lembrando que no INPUT vocÃª pode alterar o prompt, mas nao se deve apagar a palavra'''{transcription}''' pois Ã© ela que sera substituida pela transcriÃ§Ã£o do video, considere ela como uma variavel, para ligar com prompt + transcription do audio do video. Com o prompt(Template ou sua personalizaÃ§Ã£o ou duvida em relaÃ§ao a transcriÃ§Ã£o) + a transcriÃ§Ã£o do video a IA ira gerar o texto final

## ğŸŒ DemonstraÃ§Ã£o do app na web:

### Web:
<div>
  <img width='800'src='https://github.com/PedrohvFernandes/nlw-ia/blob/main/NLWIATRANSCRIPTIONWEB/public/Web/Sreen1.png'/>
  <img width='800'src='https://github.com/PedrohvFernandes/nlw-ia/blob/main/NLWIATRANSCRIPTIONWEB/public/Web/Screen2.png'/>
</div>



### Mobile: Em preparamento

## âœ¨Tecnologias:

### Principais Stacks:

- React
- shadcn/ui
- ffmpeg
- WebAssembly
- radix-ui
- ai(vercel) para front-end e back-end
- clsx
- openai
- TypeScript
- Node
- Vite
- fastify
- Sqlite
- Axios

### Secundarias Stacks:

- TailwindCSS
- Prisma(ORM)
- lucide-react
- zod

## ğŸ› ï¸ Features:

- Upload de video + transcriÃ§Ã£o desse video para mp3 e de mp3 para texto
- Prompts ja personalizados para gerar um texto final
- Resultado final, ou seja o texto final: Prompt(Template do que perguntar para ia em relaÃ§Ã£o ao transcription do video) + transcription do video(Texto gerado pelo modelo whisper-1) = Texto final(Texto gerado pelo chatgpt 3) para o usuario ter uma ideia ou usar aquilo mesmo como resultado final

## ğŸ› ï¸ Futuras Features e AtualizaÃ§Ãµes:

- Cadastro e login de usuarios
- Theme Light

## ğŸ‘¨â€ğŸ’» Autor:

- Linkedin: https://www.linkedin.com/in/pedro-henrique-vieira-fernandes
- Git: https://github.com/PedrohvFernandes
- Instagram: pedro17fernandes
- portfolio: https://pedrohvfernandes-web-page-portfolio.vercel.app

